{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbd1d904",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0 pyspark-shell'\n",
    "\n",
    "# home\n",
    "#hostip = \"192.168.1.101\" \n",
    "\n",
    "\n",
    "# library\n",
    "hostip = '10.192.1.37'\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2260ca68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "from time import sleep\n",
    "from json import dumps\n",
    "from kafka3 import KafkaProducer\n",
    "import random\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from pymongo import MongoClient\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, split, element_at, when\n",
    "import pygeohash as pgh\n",
    "import json\n",
    "from pprint import pprint\n",
    "import datetime\n",
    "\n",
    "#Initialize our spark session with \n",
    "#threads = #logicalCPU and the given application name.\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .master('local[*]')\n",
    "    .appName('Spark Streaming from Kafka into MongoDB')\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e47a756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a streaming dataframe with options \n",
    "# providing the bootstrap server(s) and topic name.\n",
    "\n",
    "topic_stream_df1 = (\n",
    "    spark.readStream.format('kafka')\n",
    "    .option('kafka.bootstrap.servers', f'{hostip}:9092')\n",
    "    .option('subscribe', 'PartB1')\n",
    "    .option(\"failOnDataLoss\", \"false\")\n",
    "    .load()\n",
    ")\n",
    "\n",
    "union_stream = topic_stream_df1\n",
    "\n",
    "stream = union_stream.selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04e01c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def process_data(batch_df, batch_id):\n",
    "    \n",
    "    # print(f\"Processing batch: {batch_id}\")\n",
    "    collected_data = batch_df.collect()\n",
    "    \n",
    "    # this climate will go to the inside to database\n",
    "    climate = {}\n",
    "    \n",
    "    # initial list for calculating stage\n",
    "    initial_AQUA = []\n",
    "    initial_TERA = []\n",
    "\n",
    "    try:\n",
    "        if len(collected_data) > 0:\n",
    "            \n",
    "            \n",
    "            for raw in collected_data:\n",
    "                \n",
    "                # make json format\n",
    "                data = raw.asDict()\n",
    "                data = data['value']\n",
    "                data = json.loads(data)\n",
    "                \n",
    "                \n",
    "                # data pre processing based on producer\n",
    "                if data['producer'] == 'producer1':\n",
    "                    data['latitude'] = float(data['latitude'])\n",
    "                    data['longitude'] = float(data['longitude'])\n",
    "                    data['air_temperature_celcius'] = float(data['air_temperature_celcius'])\n",
    "                    data['relative_humidity'] = float(data['relative_humidity'])\n",
    "                    data['windspeed_knots'] = float(data['windspeed_knots'])\n",
    "                    data['max_wind_speed'] = float(data['max_wind_speed'])\n",
    "                    data['GHI_w/m2'] = float(data['GHI_w/m2'])                                \n",
    "                    created_time_obj = datetime.datetime.strptime(data['created_time'], \"%Y-%m-%dT%H:%M:%S\")\n",
    "                    formatted_time = created_time_obj.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                    data['created_time'] = formatted_time\n",
    "                    \n",
    "                    climate = data\n",
    "                    \n",
    "                elif data['producer'] == 'producer2':\n",
    "                    data['latitude'] = float(data['latitude'])\n",
    "                    data['longitude'] = float(data['longitude'])\n",
    "                    data['confidence'] = float(data['confidence'])\n",
    "                    data['surface_temperature_celcius'] = float(data['surface_temperature_celcius'])\n",
    "                    created_time_obj = datetime.datetime.strptime(data['created_time'], \"%Y-%m-%dT%H:%M:%S\")\n",
    "                    formatted_time = created_time_obj.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                    data['created_time'] = formatted_time\n",
    "                    initial_AQUA.append(data)\n",
    "                    \n",
    "                else:\n",
    "                    data['latitude'] = float(data['latitude'])\n",
    "                    data['longitude'] = float(data['longitude'])\n",
    "                    data['confidence'] = float(data['confidence'])\n",
    "                    data['surface_temperature_celcius'] = float(data['surface_temperature_celcius'])\n",
    "                    created_time_obj = datetime.datetime.strptime(data['created_time'], \"%Y-%m-%dT%H:%M:%S\")\n",
    "                    formatted_time = created_time_obj.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                    data['created_time'] = formatted_time\n",
    "                    initial_TERA.append(data)\n",
    "                \n",
    "                # second stage : geohash (compare climate and initial datas)       \n",
    "                temp_hotspot = []   \n",
    "\n",
    "                # Process climate data\n",
    "                if climate != {} :\n",
    "\n",
    "                    cli_long = climate['longitude']\n",
    "                    cli_lat = climate['latitude']\n",
    "            \n",
    "                    # pygeohash format\n",
    "                    cli_encode_info = pgh.encode(latitude=cli_lat, longitude=cli_long, precision=3)\n",
    "\n",
    "                    \n",
    "                    # now, need to think about the AQUA initial and TERRA initial\n",
    "                    \n",
    "                    for A_record in initial_AQUA:\n",
    "                        AQUA_encode_info = pgh.encode(latitude = A_record['latitude'], longitude = A_record['longitude'], precision = 3 )\n",
    "                        \n",
    "                        if AQUA_encode_info == cli_encode_info:\n",
    "                            A_record['sate'] = 'AQUA'\n",
    "                            temp_hotspot.append(A_record)\n",
    "                            \n",
    "                    for T_record in initial_TERA:\n",
    "                        TERA_encode_info = pgh.encode(latitude = T_record['latitude'], longitude = T_record['longitude'], precision = 3 )\n",
    "                        \n",
    "                        if TERA_encode_info == cli_encode_info:\n",
    "                            T_record['sate'] = 'TERRA'\n",
    "                            temp_hotspot.append(T_record)\n",
    "                            \n",
    "                    # Merge ‘surface temperature’ and ‘confidence’\n",
    "                    \n",
    "                    if len(temp_hotspot) > 1:\n",
    "                        \n",
    "                        # checking enter here\n",
    "                        # print(\"alright, need to merge ~ \")\n",
    "                        \n",
    "                        merged_hotspot = list()\n",
    "                        \n",
    "                        merge_AQUA = list()\n",
    "                        merge_TERA = list()\n",
    "                        \n",
    "                        for hotspot_info in temp_hotspot:\n",
    "                            if hotspot_info['sate'] == 'AQUA':\n",
    "                                merge_AQUA.append(hotspot_info)\n",
    "                            else:\n",
    "                                merge_TERA.append(hotspot_info)\n",
    "                                \n",
    "                        if len(merge_AQUA) > 0 and len(merge_TERA) > 0:\n",
    "                            \n",
    "                            for i in merge_AQUA:\n",
    "                                compare5_AQUA_lat = i['latitude']\n",
    "                                compare5_AQUA_long = i['longitude']\n",
    "                                \n",
    "                                for j in merge_TERA:\n",
    "                                    encode5_AQUA = pgh.encode(latitude = compare5_AQUA_lat, longitude = compare5_AQUA_long, precision = 5)\n",
    "                                    encode5_TERA = pgh.encode(latitude = j['latitude'], longitude = j['longitude'], precision = 5)\n",
    "                                    \n",
    "                                    # final check\n",
    "                                    if encode5_AQUA == encode5_TERA:\n",
    "                                        legit = dict()\n",
    "                                        \n",
    "                                        legit['avg_temperature'] = (i['surface_temperature_celcius'] + j['surface_temperature_celcius']) / 2\n",
    "                                        legit['avg_confidence'] = (i['confidence'] + j['confidence']) / 2\n",
    "                                        legit['latitude']  = compare5_AQUA_lat\n",
    "                                        legit['longitude'] = compare5_AQUA_long\n",
    "                                        \n",
    "                                        merged_hotspot.append(legit)\n",
    "                    \n",
    "\n",
    "                    # checking is the event is natural or event\n",
    "                    if len(temp_hotspot) > 0:\n",
    "                        air_temp = float(climate['air_temperature_celcius'])\n",
    "                        GHI = float(climate['GHI_w/m2'])\n",
    "                        event = 'other'\n",
    "\n",
    "                        if air_temp > 20 and GHI > 180:\n",
    "                            event = 'natural'\n",
    "\n",
    "                        for h in temp_hotspot:\n",
    "                            h['event'] = event\n",
    "                    \n",
    "                    climate['hotspot'] = temp_hotspot\n",
    "            \n",
    "                    try:\n",
    "                        db.hotspot.insert_one(climate)\n",
    "                        \n",
    "                    except pymongo.errors.DuplicateKeyError:\n",
    "                        # This key has already in the database, so shouldn't use it.\n",
    "                        pass\n",
    "                    \n",
    "                    except Exception as ex:\n",
    "                        \n",
    "                        print(\"An error occurred:\", ex)\n",
    "\n",
    "\n",
    "        \n",
    "    except Exception as ex:\n",
    "        print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6a48a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_writer = (\n",
    "    stream\n",
    "    .writeStream\n",
    "    .foreachBatch(process_data)\n",
    "    .outputMode('append')\n",
    "    .trigger(processingTime='10 seconds')\n",
    "    .start()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b06852fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# home\n",
    "# client = MongoClient('mongodb://192.168.1.101:27017/')\n",
    "\n",
    "# library\n",
    "client = MongoClient('mongodb://10.192.1.37:27017/')\n",
    "\n",
    "\n",
    "# list of database before we delete\n",
    "result = client.list_database_names()\n",
    "#print(result)\n",
    "\n",
    "# make database\n",
    "db = client.fit3182_assignment1_db\n",
    "\n",
    "# add new collection into new database\n",
    "db.hotspot.drop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ce7946f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping query after timeout.\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "def stop_db_writer():\n",
    "    print('Stopping query after timeout.')\n",
    "    db_writer.stop()\n",
    "\n",
    "try:\n",
    "    # it will automatically stop with  stop_db_writer fuction, 5 min\n",
    "    timer = threading.Timer(300, stop_db_writer)\n",
    "    timer.start()\n",
    "    \n",
    "    # wait till it finish\n",
    "    db_writer.awaitTermination()\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    print('Interrupted by CTRL-C. Stopping query.')\n",
    "    db_writer.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02652cee",
   "metadata": {},
   "source": [
    "There will be an error if the key (_id) has been collusion, therefore, i used try and except( Duplicate Key Error) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9ffd242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('664f1ee0c7ecaa7150582685'), 'latitude': -37.863, 'longitude': 144.17, 'air_temperature_celcius': 18.0, 'relative_humidity': 57.5, 'windspeed_knots': 16.1, 'max_wind_speed': 21.0, 'precipitation ': ' 0.00G', 'GHI_w/m2': 145.0, 'created_time': '2024-02-07 00:00:00', 'producer': 'producer1', 'hotspot': []}\n",
      "{'_id': ObjectId('664f1eeac7ecaa7150582686'), 'latitude': -37.608, 'longitude': 149.282, 'air_temperature_celcius': 22.0, 'relative_humidity': 62.7, 'windspeed_knots': 7.6, 'max_wind_speed': 18.1, 'precipitation ': ' 0.00I', 'GHI_w/m2': 169.0, 'created_time': '2024-02-08 00:00:00', 'producer': 'producer1', 'hotspot': []}\n",
      "{'_id': ObjectId('664f1ef4c7ecaa7150582687'), 'latitude': -38.127, 'longitude': 143.82, 'air_temperature_celcius': 9.0, 'relative_humidity': 44.0, 'windspeed_knots': 2.8, 'max_wind_speed': 8.0, 'precipitation ': ' 0.00I', 'GHI_w/m2': 81.0, 'created_time': '2024-02-09 00:00:00', 'producer': 'producer1', 'hotspot': []}\n",
      "{'_id': ObjectId('664f1efec7ecaa7150582688'), 'latitude': -36.3328, 'longitude': 146.0355, 'air_temperature_celcius': 7.0, 'relative_humidity': 37.2, 'windspeed_knots': 6.2, 'max_wind_speed': 16.9, 'precipitation ': ' 0.08G', 'GHI_w/m2': 66.0, 'created_time': '2024-02-10 00:00:00', 'producer': 'producer1', 'hotspot': []}\n",
      "{'_id': ObjectId('664f1f08c7ecaa7150582689'), 'latitude': -37.6, 'longitude': 149.325, 'air_temperature_celcius': 16.0, 'relative_humidity': 48.1, 'windspeed_knots': 9.3, 'max_wind_speed': 12.0, 'precipitation ': ' 0.00G', 'GHI_w/m2': 139.0, 'created_time': '2024-02-11 00:00:00', 'producer': 'producer1', 'hotspot': []}\n",
      "{'_id': ObjectId('664f1f12c7ecaa715058268a'), 'latitude': -35.953, 'longitude': 141.078, 'air_temperature_celcius': 12.0, 'relative_humidity': 47.2, 'windspeed_knots': 8.8, 'max_wind_speed': 15.0, 'precipitation ': ' 0.00G', 'GHI_w/m2': 105.0, 'created_time': '2024-02-12 00:00:00', 'producer': 'producer1', 'hotspot': []}\n",
      "{'_id': ObjectId('664f1f1cc7ecaa715058268b'), 'latitude': -36.834, 'longitude': 142.524, 'air_temperature_celcius': 12.0, 'relative_humidity': 47.3, 'windspeed_knots': 9.7, 'max_wind_speed': 14.0, 'precipitation ': ' 0.02G', 'GHI_w/m2': 105.0, 'created_time': '2024-02-13 00:00:00', 'producer': 'producer1', 'hotspot': []}\n",
      "{'_id': ObjectId('664f1f26c7ecaa715058268c'), 'latitude': -37.886, 'longitude': 147.207, 'air_temperature_celcius': 19.0, 'relative_humidity': 54.3, 'windspeed_knots': 5.9, 'max_wind_speed': 12.0, 'precipitation ': ' 0.00I', 'GHI_w/m2': 157.0, 'created_time': '2024-02-14 00:00:00', 'producer': 'producer1', 'hotspot': []}\n",
      "{'_id': ObjectId('664f1f30c7ecaa715058268d'), 'latitude': -36.952, 'longitude': 144.972, 'air_temperature_celcius': 21.0, 'relative_humidity': 57.3, 'windspeed_knots': 5.4, 'max_wind_speed': 9.9, 'precipitation ': ' 0.00I', 'GHI_w/m2': 169.0, 'created_time': '2024-02-15 00:00:00', 'producer': 'producer1', 'hotspot': []}\n",
      "{'_id': ObjectId('664f1f3ac7ecaa715058268e'), 'latitude': -37.485, 'longitude': 148.095, 'air_temperature_celcius': 11.0, 'relative_humidity': 45.4, 'windspeed_knots': 5.2, 'max_wind_speed': 8.9, 'precipitation ': ' 0.00A', 'GHI_w/m2': 98.0, 'created_time': '2024-02-16 00:00:00', 'producer': 'producer1', 'hotspot': []}\n",
      "{'_id': ObjectId('664f1f44c7ecaa715058268f'), 'latitude': -36.3756, 'longitude': 143.7243, 'air_temperature_celcius': 13.0, 'relative_humidity': 47.1, 'windspeed_knots': 8.1, 'max_wind_speed': 12.0, 'precipitation ': ' 0.01G', 'GHI_w/m2': 114.0, 'created_time': '2024-02-17 00:00:00', 'producer': 'producer1', 'hotspot': []}\n",
      "{'_id': ObjectId('664f1f4ec7ecaa7150582690'), 'latitude': -37.238, 'longitude': 141.145, 'air_temperature_celcius': 8.0, 'relative_humidity': 41.6, 'windspeed_knots': 8.3, 'max_wind_speed': 15.9, 'precipitation ': ' 0.24G', 'GHI_w/m2': 73.0, 'created_time': '2024-02-18 00:00:00', 'producer': 'producer1', 'hotspot': []}\n",
      "{'_id': ObjectId('664f1f58c7ecaa7150582691'), 'latitude': -36.7685, 'longitude': 142.7134, 'air_temperature_celcius': 14.0, 'relative_humidity': 48.2, 'windspeed_knots': 12.5, 'max_wind_speed': 19.0, 'precipitation ': ' 0.03G', 'GHI_w/m2': 122.0, 'created_time': '2024-02-19 00:00:00', 'producer': 'producer1', 'hotspot': []}\n",
      "{'_id': ObjectId('664f1f62c7ecaa7150582692'), 'latitude': -36.4274, 'longitude': 142.1944, 'air_temperature_celcius': 22.0, 'relative_humidity': 46.9, 'windspeed_knots': 12.9, 'max_wind_speed': 19.0, 'precipitation ': ' 0.00I', 'GHI_w/m2': 193.0, 'created_time': '2024-02-20 00:00:00', 'producer': 'producer1', 'hotspot': [{'latitude': -36.3539, 'longitude': 142.1894, 'confidence': 53.0, 'surface_temperature_celcius': 53.0, 'created_time': '2024-01-01 17:54:11', 'producer': 'producer3', 'sate': 'TERRA', 'event': 'natural'}]}\n",
      "{'_id': ObjectId('664f1f6cc7ecaa7150582693'), 'latitude': -37.642, 'longitude': 149.263, 'air_temperature_celcius': 20.0, 'relative_humidity': 55.8, 'windspeed_knots': 10.5, 'max_wind_speed': 15.9, 'precipitation ': ' 0.01G', 'GHI_w/m2': 163.0, 'created_time': '2024-02-21 00:00:00', 'producer': 'producer1', 'hotspot': []}\n",
      "{'_id': ObjectId('664f1f76c7ecaa7150582694'), 'latitude': -37.583, 'longitude': 149.316, 'air_temperature_celcius': 25.0, 'relative_humidity': 58.3, 'windspeed_knots': 12.2, 'max_wind_speed': 22.0, 'precipitation ': ' 0.04G', 'GHI_w/m2': 199.0, 'created_time': '2024-02-22 00:00:00', 'producer': 'producer1', 'hotspot': []}\n",
      "{'_id': ObjectId('664f1f80c7ecaa7150582695'), 'latitude': -35.957, 'longitude': 141.088, 'air_temperature_celcius': 9.0, 'relative_humidity': 42.4, 'windspeed_knots': 7.2, 'max_wind_speed': 9.9, 'precipitation ': ' 0.00I', 'GHI_w/m2': 82.0, 'created_time': '2024-02-23 00:00:00', 'producer': 'producer1', 'hotspot': []}\n",
      "{'_id': ObjectId('664f1f8ac7ecaa7150582696'), 'latitude': -38.167, 'longitude': 143.841, 'air_temperature_celcius': 21.0, 'relative_humidity': 58.1, 'windspeed_knots': 5.3, 'max_wind_speed': 11.1, 'precipitation ': ' 0.00G', 'GHI_w/m2': 168.0, 'created_time': '2024-02-24 00:00:00', 'producer': 'producer1', 'hotspot': []}\n",
      "{'_id': ObjectId('664f1f94c7ecaa7150582697'), 'latitude': -36.759, 'longitude': 144.158, 'air_temperature_celcius': 14.0, 'relative_humidity': 52.5, 'windspeed_knots': 7.0, 'max_wind_speed': 13.0, 'precipitation ': ' 0.00G', 'GHI_w/m2': 118.0, 'created_time': '2024-02-25 00:00:00', 'producer': 'producer1', 'hotspot': [{'latitude': -36.6029, 'longitude': 144.6259, 'confidence': 100.0, 'surface_temperature_celcius': 115.0, 'created_time': '2024-01-01 22:52:45', 'producer': 'producer2', 'sate': 'AQUA', 'event': 'other'}]}\n",
      "{'_id': ObjectId('664f1f9ec7ecaa7150582698'), 'latitude': -36.0201, 'longitude': 143.7775, 'air_temperature_celcius': 18.0, 'relative_humidity': 55.6, 'windspeed_knots': 8.2, 'max_wind_speed': 12.0, 'precipitation ': ' 0.00I', 'GHI_w/m2': 147.0, 'created_time': '2024-02-26 00:00:00', 'producer': 'producer1', 'hotspot': []}\n",
      "{'_id': ObjectId('664f1fa8c7ecaa7150582699'), 'latitude': -35.953, 'longitude': 141.078, 'air_temperature_celcius': 12.0, 'relative_humidity': 47.2, 'windspeed_knots': 8.8, 'max_wind_speed': 15.0, 'precipitation ': ' 0.00G', 'GHI_w/m2': 105.0, 'created_time': '2024-02-27 00:00:00', 'producer': 'producer1', 'hotspot': []}\n",
      "{'_id': ObjectId('664f1fb2c7ecaa715058269a'), 'latitude': -37.6, 'longitude': 149.325, 'air_temperature_celcius': 16.0, 'relative_humidity': 48.1, 'windspeed_knots': 9.3, 'max_wind_speed': 12.0, 'precipitation ': ' 0.00G', 'GHI_w/m2': 139.0, 'created_time': '2024-02-28 00:00:00', 'producer': 'producer1', 'hotspot': []}\n",
      "{'_id': ObjectId('664f1fbcc7ecaa715058269b'), 'latitude': -36.6686, 'longitude': 142.5195, 'air_temperature_celcius': 16.0, 'relative_humidity': 47.0, 'windspeed_knots': 12.0, 'max_wind_speed': 16.9, 'precipitation ': ' 0.00I', 'GHI_w/m2': 141.0, 'created_time': '2024-02-29 00:00:00', 'producer': 'producer1', 'hotspot': []}\n",
      "{'_id': ObjectId('664f1fc6c7ecaa715058269c'), 'latitude': -36.779, 'longitude': 146.108, 'air_temperature_celcius': 13.0, 'relative_humidity': 42.0, 'windspeed_knots': 11.4, 'max_wind_speed': 16.9, 'precipitation ': ' 0.00G', 'GHI_w/m2': 119.0, 'created_time': '2024-03-01 00:00:00', 'producer': 'producer1', 'hotspot': []}\n",
      "{'_id': ObjectId('664f1fd0c7ecaa715058269d'), 'latitude': -37.8147, 'longitude': 143.1062, 'air_temperature_celcius': 17.0, 'relative_humidity': 46.4, 'windspeed_knots': 9.5, 'max_wind_speed': 20.0, 'precipitation ': ' 0.00I', 'GHI_w/m2': 150.0, 'created_time': '2024-03-02 00:00:00', 'producer': 'producer1', 'hotspot': []}\n",
      "{'_id': ObjectId('664f1fdac7ecaa715058269e'), 'latitude': -37.477, 'longitude': 148.097, 'air_temperature_celcius': 8.0, 'relative_humidity': 42.6, 'windspeed_knots': 2.0, 'max_wind_speed': 6.0, 'precipitation ': ' 0.00I', 'GHI_w/m2': 73.0, 'created_time': '2024-03-03 00:00:00', 'producer': 'producer1', 'hotspot': [{'latitude': -37.368, 'longitude': 148.05, 'confidence': 79.0, 'surface_temperature_celcius': 53.0, 'created_time': '2024-01-01 00:45:11', 'producer': 'producer2', 'sate': 'AQUA', 'event': 'other'}]}\n",
      "{'_id': ObjectId('664f1fe4c7ecaa715058269f'), 'latitude': -36.6312, 'longitude': 142.5058, 'air_temperature_celcius': 17.0, 'relative_humidity': 52.5, 'windspeed_knots': 5.7, 'max_wind_speed': 11.1, 'precipitation ': ' 0.00I', 'GHI_w/m2': 143.0, 'created_time': '2024-03-04 00:00:00', 'producer': 'producer1', 'hotspot': [{'latitude': -36.8158, 'longitude': 142.8794, 'confidence': 66.0, 'surface_temperature_celcius': 43.0, 'created_time': '2024-01-01 17:01:25', 'producer': 'producer3', 'sate': 'TERRA', 'event': 'other'}]}\n",
      "{'_id': ObjectId('664f1feec7ecaa71505826a0'), 'latitude': -37.692, 'longitude': 143.593, 'air_temperature_celcius': 14.0, 'relative_humidity': 45.8, 'windspeed_knots': 6.5, 'max_wind_speed': 9.9, 'precipitation ': ' 0.00G', 'GHI_w/m2': 124.0, 'created_time': '2024-03-05 00:00:00', 'producer': 'producer1', 'hotspot': []}\n",
      "{'_id': ObjectId('664f1ff8c7ecaa71505826a1'), 'latitude': -37.453, 'longitude': 148.111, 'air_temperature_celcius': 11.0, 'relative_humidity': 45.3, 'windspeed_knots': 10.6, 'max_wind_speed': 16.9, 'precipitation ': ' 0.08G', 'GHI_w/m2': 98.0, 'created_time': '2024-03-06 00:00:00', 'producer': 'producer1', 'hotspot': []}\n"
     ]
    }
   ],
   "source": [
    "cursor = db.hotspot.find({})\n",
    "for document in cursor:\n",
    "    print(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dd7b1e",
   "metadata": {},
   "source": [
    "The below function which is \"process_data2\" is the fucntion for in case if merging is not working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4825664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data2(batch_df, batch_id):\n",
    "    \n",
    "    # print(f\"Processing batch: {batch_id}\")\n",
    "    collected_data = batch_df.collect()\n",
    "    \n",
    "    climate = {}\n",
    "    hotspot_lst = []\n",
    "\n",
    "    try:\n",
    "        if len(collected_data) > 0:\n",
    "            \n",
    "            \n",
    "            for raw in collected_data:\n",
    "                \n",
    "                # make json format\n",
    "                data = raw.asDict()\n",
    "                data = data['value']\n",
    "                data = json.loads(data)\n",
    "                \n",
    "                \n",
    "                # data pre processing based on producer\n",
    "                if data['producer'] == 'producer1':\n",
    "                    data['latitude'] = float(data['latitude'])\n",
    "                    data['longitude'] = float(data['longitude'])\n",
    "                    data['air_temperature_celcius'] = float(data['air_temperature_celcius'])\n",
    "                    data['relative_humidity'] = float(data['relative_humidity'])\n",
    "                    data['windspeed_knots'] = float(data['windspeed_knots'])\n",
    "                    data['max_wind_speed'] = float(data['max_wind_speed'])\n",
    "                    data['GHI_w/m2'] = float(data['GHI_w/m2'])                                \n",
    "                    data['created_time'] = datetime.datetime.strptime(data['created_time'], \"%Y-%m-%d\")     \n",
    "                    climate = data\n",
    "                    \n",
    "                elif data['producer'] in ['producer2', 'producer3']:\n",
    "                    data['latitude'] = float(data['latitude'])\n",
    "                    data['longitude'] = float(data['longitude'])\n",
    "                    data['confidence'] = float(data['confidence'])\n",
    "                    data['surface_temperature_celcius'] = float(data['surface_temperature_celcius'])\n",
    "                    data['created_time'] = datetime.datetime.strptime(data['created_time'], '%H:%M:%S') \n",
    "                    hotspot_lst.append(data)\n",
    "                \n",
    "        temp_hotspot = []   \n",
    "        \n",
    "        # Process climate data\n",
    "        if climate != {} :\n",
    "\n",
    "            cli_long = climate['longitude']\n",
    "            cli_lat = climate['latitude']\n",
    "            \n",
    "            # pygeohash format\n",
    "            cli_encode_info = pgh.encode(latitude=cli_lat, longitude=cli_long, precision=3)\n",
    "\n",
    "            if len(hotspot_lst) != 0:\n",
    "                for hotspot_record in hotspot_lst:\n",
    "                    hotspot_encode_info = pgh.encode(latitude=hotspot_record['latitude'], longitude=hotspot_record['longitude'], precision=3)\n",
    "                    if hotspot_encode_info == cli_encode_info:\n",
    "                        temp_hotspot.append(hotspot_record)\n",
    "                        \n",
    "                        \n",
    "            ####\n",
    "            # the part could improve more with \"merging\"\n",
    "            # I tried my best for merging the similar location,\n",
    "            # However, I couldnt make it work.\n",
    "            \n",
    "            \n",
    "#             if len(temp_hotspot) >= 2:\n",
    "#                 #print(\"time to merge!\")\n",
    "#                 merging_hotspot = []\n",
    "\n",
    "#                 for i in temp_hotspot:\n",
    "#                     for j in temp_hotspot:\n",
    "#                         first_encode_info  = pgh.encode(latitude=i['latitude'], longitude=i['longitude'], precision=3)\n",
    "#                         second_encode_info = pgh.encode(latitude=j['latitude'], longitude=j['longitude'], precision=3)\n",
    "                        \n",
    "#                         if first_encode_info == second_encode_info:\n",
    "#                             fire = {}\n",
    "#                             fire['avg_temperature'] = (i['surface_temperature_celcius'] + j['surface_temperature_celcius']) / 2\n",
    "#                             fire['avg_confidence'] = (i['confidence'] + j['confidence']) / 2\n",
    "#                             fire['latitude'] = hot_latitude\n",
    "#                             fire['longitude'] = hot_longitude\n",
    "                            \n",
    "#                             merging_hotspot.append(fire)\n",
    "#                             #print(\"fire event here!\", merging_hotspot)\n",
    "#                             temp_hotspot = merging_hotspot\n",
    "            ####\n",
    "            \n",
    "            \n",
    "            # checking is the event is natural or event\n",
    "            if len(temp_hotspot) > 0:\n",
    "                air_temp = float(climate['air_temperature_celcius'])\n",
    "                GHI = float(climate['GHI_w/m2'])\n",
    "                event = 'other'\n",
    "                \n",
    "                if air_temp > 20 and GHI > 180:\n",
    "                    event = 'natural'\n",
    "                \n",
    "                for h in temp_hotspot:\n",
    "                    h['event'] = event\n",
    "                    \n",
    "            climate['hotspot'] = temp_hotspot\n",
    "            \n",
    "            try:\n",
    "                db.hotspot.insert_one(climate)\n",
    "            except Exception as ex:\n",
    "                print(ex)\n",
    "        \n",
    "        \n",
    "    except Exception as ex:\n",
    "        print(ex)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
