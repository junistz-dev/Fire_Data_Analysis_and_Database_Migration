{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb10776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Publishing records..\n"
     ]
    }
   ],
   "source": [
    "# import statements\n",
    "from pymongo import MongoClient\n",
    "\n",
    "import csv\n",
    "from time import sleep\n",
    "from json import dumps\n",
    "from kafka3 import KafkaProducer\n",
    "import random\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import json\n",
    "import pymongo\n",
    "\n",
    "#hostip = '192.168.1.101'\n",
    "\n",
    "# home\n",
    "# client = MongoClient('mongodb://192.168.1.101:27017/')\n",
    "\n",
    "# library\n",
    "hostip = '10.192.0.143'\n",
    "client = MongoClient('mongodb://10.192.0.143:27017/')\n",
    "\n",
    "\n",
    "db = client.fit3182_assignment1_db\n",
    "\n",
    "collection = db.merged_history\n",
    "\n",
    "def publish_message(producer_instance, topic_name, key, value):\n",
    "    try:\n",
    "        key_bytes = bytes(key, encoding='utf-8')\n",
    "        value_bytes = bytes(value, encoding='utf-8')\n",
    "        \n",
    "        producer_instance.send(topic_name, key = key_bytes, value=value_bytes)\n",
    "        \n",
    "        producer_instance.flush()\n",
    "        print('Message published successfully. Data: ' + str(value))\n",
    "        \n",
    "    except Exception as ex:\n",
    "        print('Exception in publishing message.')\n",
    "        print(str(ex))\n",
    "        \n",
    "def connect_kafka_producer():\n",
    "    _producer = None\n",
    "    try:\n",
    "        _producer = KafkaProducer(bootstrap_servers=[f'{hostip}:9092'],\n",
    "                                  api_version=(0, 10))\n",
    "    except Exception as ex:\n",
    "        print('Exception while connecting Kafka.')\n",
    "        print(str(ex))\n",
    "    finally:\n",
    "        return _producer\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    topic = 'PartB1'\n",
    "    array = []\n",
    "    \n",
    "    # for finding the latest date.\n",
    "    with open('climate_streaming.csv', 'r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "\n",
    "        for row in reader:  \n",
    "            array.append(row)\n",
    "            \n",
    "    print('Publishing records..')\n",
    "    producer = connect_kafka_producer()\n",
    "    \n",
    "    # finding the latest date in the climate data with sort - descending\n",
    "    latest_record = collection.find().sort([('date', pymongo.DESCENDING)]).limit(1)\n",
    "    latest_date = latest_record[0]['date']\n",
    "    \n",
    "    \n",
    "    # pick data with random.randrange\n",
    "    for _ in range(len(array)):\n",
    "        random_number = random.randrange(0, len(array))\n",
    "        random_data = array[random_number]\n",
    "        #print(random_data)\n",
    "        latest_date += dt.timedelta(days=1)    \n",
    "        \n",
    "        # set date to string \n",
    "        random_data['created_time'] = latest_date.isoformat()\n",
    "        random_data['producer'] = 'producer1'\n",
    "\n",
    "        #key = producer1\n",
    "        publish_message(producer, topic, \"producer1\", json.dumps(random_data))\n",
    "        sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52629b2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
